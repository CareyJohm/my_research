{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "from scipy.spatial import cKDTree\n",
    "import pyfits, mechanize, bz2, os\n",
    "from matplotlib import pyplot as pl\n",
    "from numpy import *\n",
    "from scipy.optimize import leastsq\n",
    "import astropy.stats as sta\n",
    "from scipy import ndimage\n",
    "from glob import glob\n",
    "import pandas as pd  #為了讀csv檔。csv檔是以逗點分割的檔案。\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from astropy.io import ascii\n",
    "import concurrent.futures\n",
    "from time import sleep\n",
    "from astropy.table import Table\n",
    "import math as m\n",
    "import gzip\n",
    "import patoolib\n",
    "import glob\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('D:\\kepler_ptf_research\\k2_c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ptf_ha_positive_sub_k2c1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'201134862'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(int(df['EPIC'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('D:\\kepler_ptf_research\\k2_c1\\python_PTF_data_k2c1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PTF_20170209'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a ='PTF_201702094500_c_p_scie_t104800_u030813636_f11_p002433_c06.ctlg'\n",
    "a[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_epic(epic):\n",
    "    ID = \"ktwo\"+str(int(epic))\n",
    "    os.chdir(\"D:/kepler_ptf_research/k2_c1/python_PTF_data_k2c1//\"+ID+\"_C1\")\n",
    "    f11 = glob.glob('*f11*')\n",
    "    f12 = glob.glob('*f12*')\n",
    "    if f11[0][0:12] == f12[0][0:12]:\n",
    "        epic_list.append(int(epic))\n",
    "    else:\n",
    "        print 'These were observed on different day'\n",
    "    os.chdir(\"D:/kepler_ptf_research/k2_c1/python_PTF_data_k2c1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epic_list =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n",
      "These were observed on different day\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df['EPIC'])):\n",
    "    find_epic(df['EPIC'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1792"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201140566, int)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epic_list[0], type(epic_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('D:\\kepler_ptf_research\\k2_c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('lamostdr4_ptf_k2c1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epic2_list = []\n",
    "ew_list = []\n",
    "ewerr_list = []\n",
    "ha_sub = []\n",
    "for i in range(len(df2['EPIC'])):\n",
    "    if int(df2['EPIC'][i]) in epic_list:\n",
    "        epic2_list.append(df2['EPIC'][i])\n",
    "        ew_list.append(df2['ewha'][i])\n",
    "        ewerr_list.append(df2['ewha_err'][i])\n",
    "        ha_sub.append(df2['HA663-HA656'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epic2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201136343"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(df['EPIC'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ha_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pl.scatter(ewha_new2, nor_hasub)\n",
    "#pl.errorbar(ewha_new2, hasub, xerr = ewha_err_new, fmt='o', ecolor='g')\n",
    "pl.errorbar(ha_sub, ew_list, yerr = ewerr_list, markersize = 3.5, fmt='o' ,ecolor='g')\n",
    "#pl.xlabel('EW_H$a$')\n",
    "#pl.ylabel('NHSV')\n",
    "pl.ylabel('EW_H$a$')\n",
    "pl.xlabel('ha663-ha656')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.109318733215\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ew_list)):\n",
    "    if ew_list[i] == min(ew_list):\n",
    "        print ha_sub[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_obs_match(epic):\n",
    "    \n",
    "    #find date_obs of each lamost data\n",
    "    os.chdir('D:\\kepler_ptf_research\\k2_c1\\python_LAMOST_data_k2c1\\DR4\\ktwo'+str(epic)+'_C1')\n",
    "    lamost_fits = glob.glob('*fits')\n",
    "    lam = pyfits.open(lamost_fits[0])\n",
    "    lamost_data = lam[0].header['DATE']\n",
    "    \n",
    "    #find date_obs of each ptf data\n",
    "    os.chdir('D:\\kepler_ptf_research\\k2_c1\\python_PTF_data_k2c1\\ktwo'+str(epic)+'_C1')\n",
    "    ptf_fits = glob.glob('*ctlg')\n",
    "    ptf = pyfits.open(ptf_fits[0])\n",
    "    ptf_date = ptf[2].header['DATE-OBS']\n",
    "    \n",
    "    if lamost_data[:10] == ptf_date[:10]:\n",
    "        epic.appand(epic)\n",
    "    else:\n",
    "        print epic,'The data of PTF and LAMOST are not matched'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epic = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201951507 The data of PTF and LAMOST are not matched\n",
      "201617526 The data of PTF and LAMOST are not matched\n",
      "201903390 The data of PTF and LAMOST are not matched\n",
      "201498396 The data of PTF and LAMOST are not matched\n",
      "201664337 The data of PTF and LAMOST are not matched\n",
      "201386095 The data of PTF and LAMOST are not matched\n",
      "201641211 The data of PTF and LAMOST are not matched\n",
      "201560437 The data of PTF and LAMOST are not matched\n",
      "201866368 The data of PTF and LAMOST are not matched\n",
      "201915687 The data of PTF and LAMOST are not matched\n",
      "201659277 The data of PTF and LAMOST are not matched\n",
      "201908324 The data of PTF and LAMOST are not matched\n",
      "201895565 The data of PTF and LAMOST are not matched\n",
      "201577109 The data of PTF and LAMOST are not matched\n",
      "201727980 The data of PTF and LAMOST are not matched\n",
      "201436683 The data of PTF and LAMOST are not matched\n",
      "201909533 The data of PTF and LAMOST are not matched\n",
      "201914589 The data of PTF and LAMOST are not matched\n",
      "201639545 The data of PTF and LAMOST are not matched\n",
      "201795220 The data of PTF and LAMOST are not matched\n",
      "201394380 The data of PTF and LAMOST are not matched\n",
      "201722715 The data of PTF and LAMOST are not matched\n",
      "201596050 The data of PTF and LAMOST are not matched\n",
      "201514262 The data of PTF and LAMOST are not matched\n",
      "201416311 The data of PTF and LAMOST are not matched\n",
      "201295538 The data of PTF and LAMOST are not matched\n",
      "201638723 The data of PTF and LAMOST are not matched\n",
      "201842163 The data of PTF and LAMOST are not matched\n",
      "201813040 The data of PTF and LAMOST are not matched\n",
      "201748955 The data of PTF and LAMOST are not matched\n",
      "201886530 The data of PTF and LAMOST are not matched\n",
      "201754501 The data of PTF and LAMOST are not matched\n",
      "201819318 The data of PTF and LAMOST are not matched\n",
      "201410114 The data of PTF and LAMOST are not matched\n",
      "201596733 The data of PTF and LAMOST are not matched\n",
      "201511626 The data of PTF and LAMOST are not matched\n",
      "201506518 The data of PTF and LAMOST are not matched\n",
      "201605484 The data of PTF and LAMOST are not matched\n",
      "201904601 The data of PTF and LAMOST are not matched\n",
      "201849532 The data of PTF and LAMOST are not matched\n",
      "201625637 The data of PTF and LAMOST are not matched\n",
      "201745007 The data of PTF and LAMOST are not matched\n",
      "201747732 The data of PTF and LAMOST are not matched\n",
      "201785646 The data of PTF and LAMOST are not matched\n",
      "201687988 The data of PTF and LAMOST are not matched\n",
      "201675785 The data of PTF and LAMOST are not matched\n",
      "201630280 The data of PTF and LAMOST are not matched\n",
      "201658661 The data of PTF and LAMOST are not matched\n",
      "201265713 The data of PTF and LAMOST are not matched\n",
      "201425748 The data of PTF and LAMOST are not matched\n",
      "201464921 The data of PTF and LAMOST are not matched\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(epic2_list)):\n",
    "    data_obs_match(epic2_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_obs_match_month(epic):\n",
    "    \n",
    "    #find date_obs of each lamost data\n",
    "    os.chdir('D:\\kepler_ptf_research\\k2_c1\\python_LAMOST_data_k2c1\\DR4\\ktwo'+str(epic)+'_C1')\n",
    "    lamost_fits = glob.glob('*fits')\n",
    "    lam = pyfits.open(lamost_fits[0])\n",
    "    lamost_data = lam[0].header['DATE']\n",
    "    \n",
    "    #find date_obs of each ptf data\n",
    "    os.chdir('D:\\kepler_ptf_research\\k2_c1\\python_PTF_data_k2c1\\ktwo'+str(epic)+'_C1')\n",
    "    ptf_fits = glob.glob('*ctlg')\n",
    "    ptf = pyfits.open(ptf_fits[0])\n",
    "    ptf_date = ptf[2].header['DATE-OBS']\n",
    "    \n",
    "    if lamost_data[:7] == ptf_date[:7]:\n",
    "        epic.appand(epic)\n",
    "    else:\n",
    "        print epic,'The date of PTF and LAMOST are not matched.','lam:',lamost_data[:7], 'ptf:', ptf_date[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201951507 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201617526 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201903390 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201498396 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201664337 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201386095 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2011-06\n",
      "201641211 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201560437 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201866368 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201915687 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201659277 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201908324 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201895565 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201577109 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201727980 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201436683 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201909533 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201914589 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201639545 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201795220 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201394380 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2011-06\n",
      "201722715 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201596050 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201514262 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201416311 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201295538 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2014-01\n",
      "201638723 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201842163 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201813040 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201748955 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201886530 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201754501 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2011-06\n",
      "201819318 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201410114 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201596733 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201511626 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201506518 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201605484 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201904601 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201849532 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201625637 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201745007 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201747732 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201785646 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-04\n",
      "201687988 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201675785 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2011-06\n",
      "201630280 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-03\n",
      "201658661 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201265713 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2012-05\n",
      "201425748 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n",
      "201464921 The date of PTF and LAMOST are not matched. lam: 2016-12 ptf: 2013-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(epic2_list)):\n",
    "    data_obs_match_month(epic2_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
